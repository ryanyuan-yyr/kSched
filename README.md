# Maximizing GPU Performance with *ko-Sched*: An Offline Tuner for CUDA Kernel Slicing

This repo contains all the source code of ko-Sched, an offline tuner for CUDA kernel slicing. For the design, implementation details and performance evaluation, see [the thesis](https://github.com/ryanyuan-yyr/undergrad-thesis-koSched). 

## Build

Ko-Sched is built and run on a Linux OS with [CUDA Toolkit](https://developer.nvidia.com/cuda-toolkit) installed. 

3 binaries are presented, whose source codes are placed under `./src`. 

1. `automatic_config`, built with `make automatic_config`
   The core binary of ko-Sched, searches for the optimal subkernel configuration for designated co-scheduled kernels. 

2. `eval_config`, built with `make eval_config`
   `eval_config` tests an extensive range of subkernel configurations for a theoretical optimal configuration. This helps evaluate the optimality of the results obtained by `automatic_config`. 

3. `run_tests`, built with `make run_tests`
    `run_tests` runs 2 split kernels concurrently with specifed subkernel configuration. 

`make clean` cleans all the object file generated during building. 

## Repo Structure

1. The source codes for binaries introduced above are placed under `./src`. 
2. The heart of ko-Sched is implemented in [include/kosched.cuh](include/kosched.cuh), including classes `Kernel`, `CoSchedKernels`. 
3. Some utility classes and macros are defined in [include/utility.cuh](include/utility.cuh) and [src/utility/utility.cu](src/utility/utility.cu). 
4. The test implementation used in the evaluation is located at `./tests`. 
5. The scripts used to handle the evaluation data and plot diagrams used in the paper are located at `./scripts`
6. All the data generated during the evaluation are placed in `./data`. Among which, [data/searching_results.json](data/searching_results.json) concludes the performance of ko-Sched on different GPU hardwares. Other folders stores the evaluation results for a range of subkernel configurations on a specific GPU(the name of the GPU is indicated in the folder name), generated by `eval_config`. 
7. Submodule `cuda_scheduling_examiner_mirror` is used to show the scheduling policy of NVIDIA GPU. The configuration [cuda_scheduling_examiner_mirror/configs/kernel_nonparallel.json](cuda_scheduling_examiner_mirror/configs/kernel_nonparallel.json) illustrates how the scheduling policies hinders kernel from running in parallel. The timeline view for this experiment can be found in [paper/figures/sm_level_kernel_scheduling/kernel_nonparallel.pdf](paper/figures/sm_level_kernel_scheduling/kernel_nonparallel.pdf). 
8. The LaTeX source code can be found under `./paper`. All the diagrams (in some cases, the profiling data generated by NSight Systems that the diagrams use) are in `./paper/figures`. 
